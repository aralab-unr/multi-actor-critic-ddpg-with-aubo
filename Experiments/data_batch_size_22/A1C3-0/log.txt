Logging to /home/adarshsehgal/AACHER_logs/A1C3-0
T: 50
_Q_lr: 0.001
_action_l2: 1.0
_batch_size: 22
_buffer_size: 1000000
_clip_obs: 200.0
_hidden: 128
_layers: 2
_max_u: 1.7
_network_class: multi_actor_critic:MultiActorCritic
_norm_clip: 5
_norm_eps: 0.01
_number_actors_main: 1
_number_actors_target: 1
_number_critics_main: 3
_number_critics_target: 3
_pi_lr: 0.001
_polyak: 0.95
_relative_goals: False
_scope: ddpg
central_tendency: mean
ddpg_params: {'buffer_size': 1000000, 'hidden': 128, 'layers': 2, 'network_class': 'multi_actor_critic:MultiActorCritic', 'polyak': 0.95, 'batch_size': 22, 'Q_lr': 0.001, 'pi_lr': 0.001, 'norm_eps': 0.01, 'norm_clip': 5, 'max_u': 1.7, 'action_l2': 1.0, 'clip_obs': 200.0, 'scope': 'ddpg', 'relative_goals': False, 'number_actors_main': 1, 'number_critics_main': 3, 'number_actors_target': 1, 'number_critics_target': 3}
env_name: AuboReach-v5
gamma: 0.98
make_env: <function prepare_params.<locals>.make_env at 0x7ff34d53a6a8>
n_batches: 15
n_cycles: 15
n_test_rollouts: 10
noise_eps: 0.2
random_eps: 0.3
replay_k: 4
replay_strategy: future
rl_algo: ddpg_multi_actor_critic
rollout_batch_size: 2
test_with_polyak: False
Creating a DDPGMultiActorCritic agent with action space 4 x 1.7...
Training...
-------------------------------------------
| epoch              | 0                  |
| stats_g/mean       | -0.051768653       |
| stats_g/std        | 1.0151384          |
| stats_o/mean       | -0.05062411        |
| stats_o/std        | 1.1770098          |
| test/episode       | 20.0               |
| test/mean_Q        | -3.6962852         |
| test/reward        | -349.1641455309483 |
| test/steps         | 1000.0             |
| test/success_rate  | 0.0                |
| train/episode      | 30.0               |
| train/reward       | -272.9276494382625 |
| train/steps        | 1500.0             |
| train/success_rate | 0.0                |
-------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_0.pkl ...
--------------------------------------------
| epoch              | 1                   |
| stats_g/mean       | 0.032778982         |
| stats_g/std        | 0.95782685          |
| stats_o/mean       | 0.039253436         |
| stats_o/std        | 1.095208            |
| test/episode       | 40.0                |
| test/mean_Q        | -4.2793064          |
| test/reward        | -188.1956733682715  |
| test/steps         | 2000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 60.0                |
| train/reward       | -216.40529354368442 |
| train/steps        | 3000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 2                   |
| stats_g/mean       | 0.04894098          |
| stats_g/std        | 0.9340464           |
| stats_o/mean       | 0.017515384         |
| stats_o/std        | 1.0835996           |
| test/episode       | 60.0                |
| test/mean_Q        | -4.9192433          |
| test/reward        | -207.91970811044408 |
| test/steps         | 3000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 90.0                |
| train/reward       | -206.2588035066695  |
| train/steps        | 4500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
-------------------------------------------
| epoch              | 3                  |
| stats_g/mean       | 0.03932144         |
| stats_g/std        | 0.9342673          |
| stats_o/mean       | 0.034132108        |
| stats_o/std        | 1.0627517          |
| test/episode       | 80.0               |
| test/mean_Q        | -5.1175003         |
| test/reward        | -147.1729924576715 |
| test/steps         | 4000.0             |
| test/success_rate  | 0.0                |
| train/episode      | 120.0              |
| train/reward       | -215.6768242918041 |
| train/steps        | 6000.0             |
| train/success_rate | 0.0                |
-------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 4                   |
| stats_g/mean       | 0.03896691          |
| stats_g/std        | 0.9321225           |
| stats_o/mean       | 0.03120634          |
| stats_o/std        | 1.0411525           |
| test/episode       | 100.0               |
| test/mean_Q        | -5.5931892          |
| test/reward        | -154.9234088775559  |
| test/steps         | 5000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 150.0               |
| train/reward       | -158.33276330606293 |
| train/steps        | 7500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 5                   |
| stats_g/mean       | 0.03810328          |
| stats_g/std        | 0.91808695          |
| stats_o/mean       | 0.03244751          |
| stats_o/std        | 1.0159107           |
| test/episode       | 120.0               |
| test/mean_Q        | -5.410412           |
| test/reward        | -125.69707307285272 |
| test/steps         | 6000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 180.0               |
| train/reward       | -174.6178976532001  |
| train/steps        | 9000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_5.pkl ...
--------------------------------------------
| epoch              | 6                   |
| stats_g/mean       | 0.030851185         |
| stats_g/std        | 0.91712725          |
| stats_o/mean       | 0.009597588         |
| stats_o/std        | 1.0021393           |
| test/episode       | 140.0               |
| test/mean_Q        | -4.779544           |
| test/reward        | -92.5660140909177   |
| test/steps         | 7000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 210.0               |
| train/reward       | -187.40905903770886 |
| train/steps        | 10500.0             |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
-------------------------------------------
| epoch              | 7                  |
| stats_g/mean       | 0.01432943         |
| stats_g/std        | 0.91458356         |
| stats_o/mean       | -0.002793748       |
| stats_o/std        | 0.9815729          |
| test/episode       | 160.0              |
| test/mean_Q        | -4.964838          |
| test/reward        | -81.29533856116517 |
| test/steps         | 8000.0             |
| test/success_rate  | 0.0                |
| train/episode      | 240.0              |
| train/reward       | -147.5276838248343 |
| train/steps        | 12000.0            |
| train/success_rate | 0.0                |
-------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
---------------------------------------------
| epoch              | 8                    |
| stats_g/mean       | 0.009011239          |
| stats_g/std        | 0.9104738            |
| stats_o/mean       | -0.004021327         |
| stats_o/std        | 0.9620938            |
| test/episode       | 180.0                |
| test/mean_Q        | -4.876373            |
| test/reward        | -60.54133094533834   |
| test/steps         | 9000.0               |
| test/success_rate  | 0.1                  |
| train/episode      | 270.0                |
| train/reward       | -110.75059342924959  |
| train/steps        | 13500.0              |
| train/success_rate | 0.016666666666666666 |
---------------------------------------------
New best success rate: 0.1. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 9                   |
| stats_g/mean       | 0.011677701         |
| stats_g/std        | 0.9098691           |
| stats_o/mean       | -0.00016986812      |
| stats_o/std        | 0.9497973           |
| test/episode       | 200.0               |
| test/mean_Q        | -4.6167955          |
| test/reward        | -83.93448222963227  |
| test/steps         | 10000.0             |
| test/success_rate  | 0.45                |
| train/episode      | 300.0               |
| train/reward       | -110.68674569060431 |
| train/steps        | 15000.0             |
| train/success_rate | 0.03333333333333333 |
--------------------------------------------
New best success rate: 0.45. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 10                  |
| stats_g/mean       | 0.007405462         |
| stats_g/std        | 0.91130364          |
| stats_o/mean       | -0.0027369144       |
| stats_o/std        | 0.9385698           |
| test/episode       | 220.0               |
| test/mean_Q        | -5.133129           |
| test/reward        | -99.94019273985688  |
| test/steps         | 11000.0             |
| test/success_rate  | 0.6                 |
| train/episode      | 330.0               |
| train/reward       | -121.01051325626462 |
| train/steps        | 16500.0             |
| train/success_rate | 0.08333333333333334 |
--------------------------------------------
New best success rate: 0.6. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_10.pkl ...
--------------------------------------------
| epoch              | 11                  |
| stats_g/mean       | 0.010171259         |
| stats_g/std        | 0.9127934           |
| stats_o/mean       | -0.0026860477       |
| stats_o/std        | 0.93154764          |
| test/episode       | 240.0               |
| test/mean_Q        | -4.9039283          |
| test/reward        | -86.87224740273473  |
| test/steps         | 12000.0             |
| test/success_rate  | 0.5                 |
| train/episode      | 360.0               |
| train/reward       | -119.97096546724447 |
| train/steps        | 18000.0             |
| train/success_rate | 0.2                 |
--------------------------------------------
--------------------------------------------
| epoch              | 12                  |
| stats_g/mean       | 0.0019440958        |
| stats_g/std        | 0.9105637           |
| stats_o/mean       | -0.006472362        |
| stats_o/std        | 0.9214255           |
| test/episode       | 260.0               |
| test/mean_Q        | -5.136815           |
| test/reward        | -89.61947954297395  |
| test/steps         | 13000.0             |
| test/success_rate  | 0.42500000000000004 |
| train/episode      | 390.0               |
| train/reward       | -153.44327401054068 |
| train/steps        | 19500.0             |
| train/success_rate | 0.25                |
--------------------------------------------
--------------------------------------------
| epoch              | 13                  |
| stats_g/mean       | 0.0041430956        |
| stats_g/std        | 0.9103606           |
| stats_o/mean       | -0.0049819774       |
| stats_o/std        | 0.9137517           |
| test/episode       | 280.0               |
| test/mean_Q        | -5.656348           |
| test/reward        | -92.120344723742    |
| test/steps         | 14000.0             |
| test/success_rate  | 0.225               |
| train/episode      | 420.0               |
| train/reward       | -109.15231955301414 |
| train/steps        | 21000.0             |
| train/success_rate | 0.2                 |
--------------------------------------------
--------------------------------------------
| epoch              | 14                  |
| stats_g/mean       | -0.00019519869      |
| stats_g/std        | 0.9105131           |
| stats_o/mean       | -0.007914391        |
| stats_o/std        | 0.9064871           |
| test/episode       | 300.0               |
| test/mean_Q        | -5.4015837          |
| test/reward        | -74.29551182707678  |
| test/steps         | 15000.0             |
| test/success_rate  | 0.875               |
| train/episode      | 450.0               |
| train/reward       | -167.33415877534702 |
| train/steps        | 22500.0             |
| train/success_rate | 0.15                |
--------------------------------------------
New best success rate: 0.875. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
