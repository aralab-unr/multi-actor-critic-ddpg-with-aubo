Logging to /home/adarshsehgal/AACHER_logs/A5C7-1
T: 50
_Q_lr: 0.001
_action_l2: 1.0
_batch_size: 256
_buffer_size: 1000000
_clip_obs: 200.0
_hidden: 128
_layers: 2
_max_u: 1.7
_network_class: multi_actor_critic:MultiActorCritic
_norm_clip: 5
_norm_eps: 0.01
_number_actors_main: 5
_number_actors_target: 5
_number_critics_main: 7
_number_critics_target: 7
_pi_lr: 0.001
_polyak: 0.95
_relative_goals: False
_scope: ddpg
central_tendency: mean
ddpg_params: {'buffer_size': 1000000, 'hidden': 128, 'layers': 2, 'network_class': 'multi_actor_critic:MultiActorCritic', 'polyak': 0.95, 'batch_size': 256, 'Q_lr': 0.001, 'pi_lr': 0.001, 'norm_eps': 0.01, 'norm_clip': 5, 'max_u': 1.7, 'action_l2': 1.0, 'clip_obs': 200.0, 'scope': 'ddpg', 'relative_goals': False, 'number_actors_main': 5, 'number_critics_main': 7, 'number_actors_target': 5, 'number_critics_target': 7}
env_name: AuboReach-v5
gamma: 0.98
make_env: <function prepare_params.<locals>.make_env at 0x7f4b928241e0>
n_batches: 15
n_cycles: 15
n_test_rollouts: 10
noise_eps: 0.2
random_eps: 0.3
replay_k: 4
replay_strategy: future
rl_algo: ddpg_multi_actor_critic
rollout_batch_size: 2
test_with_polyak: False
Creating a DDPGMultiActorCritic agent with action space 4 x 1.7...
Training...
-------------------------------------------
| epoch              | 0                  |
| stats_g/mean       | -0.016846584       |
| stats_g/std        | 0.9947775          |
| stats_o/mean       | -0.022131402       |
| stats_o/std        | 1.1856904          |
| test/episode       | 20.0               |
| test/mean_Q        | -3.0586429         |
| test/reward        | -233.6516876026856 |
| test/steps         | 1000.0             |
| test/success_rate  | 0.0                |
| train/episode      | 30.0               |
| train/reward       | -301.2262985759011 |
| train/steps        | 1500.0             |
| train/success_rate | 0.0                |
-------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_0.pkl ...
--------------------------------------------
| epoch              | 1                   |
| stats_g/mean       | 0.020474298         |
| stats_g/std        | 0.96013117          |
| stats_o/mean       | -0.0069469716       |
| stats_o/std        | 1.1295565           |
| test/episode       | 40.0                |
| test/mean_Q        | -3.4254184          |
| test/reward        | -144.27011506392458 |
| test/steps         | 2000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 60.0                |
| train/reward       | -226.44433685728995 |
| train/steps        | 3000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 2                   |
| stats_g/mean       | 0.01605938          |
| stats_g/std        | 0.9401854           |
| stats_o/mean       | -0.015915766        |
| stats_o/std        | 1.0823187           |
| test/episode       | 60.0                |
| test/mean_Q        | -4.245109           |
| test/reward        | -197.00557829821173 |
| test/steps         | 3000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 90.0                |
| train/reward       | -155.417269068285   |
| train/steps        | 4500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 3                   |
| stats_g/mean       | 0.021023838         |
| stats_g/std        | 0.9176535           |
| stats_o/mean       | 0.014243706         |
| stats_o/std        | 1.0508705           |
| test/episode       | 80.0                |
| test/mean_Q        | -5.1301513          |
| test/reward        | -162.1486886410492  |
| test/steps         | 4000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 120.0               |
| train/reward       | -230.06853334494798 |
| train/steps        | 6000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 4                   |
| stats_g/mean       | 0.016601445         |
| stats_g/std        | 0.90999246          |
| stats_o/mean       | 0.026953023         |
| stats_o/std        | 1.0249357           |
| test/episode       | 100.0               |
| test/mean_Q        | -4.9337454          |
| test/reward        | -117.23500728779823 |
| test/steps         | 5000.0              |
| test/success_rate  | 0.07500000000000001 |
| train/episode      | 150.0               |
| train/reward       | -149.53290132471213 |
| train/steps        | 7500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.07500000000000001. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 5                   |
| stats_g/mean       | 0.015837185         |
| stats_g/std        | 0.8984151           |
| stats_o/mean       | 0.029553734         |
| stats_o/std        | 1.0006446           |
| test/episode       | 120.0               |
| test/mean_Q        | -4.8136435          |
| test/reward        | -112.41032300075369 |
| test/steps         | 6000.0              |
| test/success_rate  | 0.25                |
| train/episode      | 180.0               |
| train/reward       | -121.29557085570823 |
| train/steps        | 9000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.25. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_5.pkl ...
--------------------------------------------
| epoch              | 6                   |
| stats_g/mean       | 0.0146145765        |
| stats_g/std        | 0.89729846          |
| stats_o/mean       | 0.027869621         |
| stats_o/std        | 0.9803355           |
| test/episode       | 140.0               |
| test/mean_Q        | -4.6415286          |
| test/reward        | -119.13481751711758 |
| test/steps         | 7000.0              |
| test/success_rate  | 0.475               |
| train/episode      | 210.0               |
| train/reward       | -102.08567642806094 |
| train/steps        | 10500.0             |
| train/success_rate | 0.03333333333333333 |
--------------------------------------------
New best success rate: 0.475. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 7                   |
| stats_g/mean       | 0.015254794         |
| stats_g/std        | 0.8896993           |
| stats_o/mean       | 0.02419027          |
| stats_o/std        | 0.96365577          |
| test/episode       | 160.0               |
| test/mean_Q        | -5.1727805          |
| test/reward        | -81.2287596601934   |
| test/steps         | 8000.0              |
| test/success_rate  | 0.65                |
| train/episode      | 240.0               |
| train/reward       | -135.333686234236   |
| train/steps        | 12000.0             |
| train/success_rate | 0.06666666666666667 |
--------------------------------------------
New best success rate: 0.65. Saving policy to /home/adarshsehgal/AACHER_logs/A5C7-1/policy_best.pkl ...
