Logging to /home/adarshsehgal/AACHER_logs/DRL-0
T: 50
_Q_lr: 0.001
_action_l2: 1.0
_batch_size: 32
_buffer_size: 1000000
_clip_obs: 200.0
_hidden: 128
_layers: 2
_max_u: 1.7
_network_class: actor_critic:ActorCritic
_norm_clip: 5
_norm_eps: 0.01
_number_actors_main: 1
_number_actors_target: 1
_number_critics_main: 3
_number_critics_target: 3
_pi_lr: 0.001
_polyak: 0.95
_relative_goals: False
_scope: ddpg
central_tendency: mean
ddpg_params: {'buffer_size': 1000000, 'hidden': 128, 'layers': 2, 'network_class': 'actor_critic:ActorCritic', 'polyak': 0.95, 'batch_size': 32, 'Q_lr': 0.001, 'pi_lr': 0.001, 'norm_eps': 0.01, 'norm_clip': 5, 'max_u': 1.7, 'action_l2': 1.0, 'clip_obs': 200.0, 'scope': 'ddpg', 'relative_goals': False, 'number_actors_main': 1, 'number_critics_main': 3, 'number_actors_target': 1, 'number_critics_target': 3}
env_name: AuboReach-v5
gamma: 0.98
make_env: <function prepare_params.<locals>.make_env at 0x7f5537b8f6a8>
n_batches: 15
n_cycles: 15
n_test_rollouts: 10
noise_eps: 0.2
random_eps: 0.3
replay_k: 4
replay_strategy: future
rl_algo: ddpg
rollout_batch_size: 2
test_with_polyak: False
Creating a DDPG agent with action space 4 x 1.7...
Training...
--------------------------------------------
| epoch              | 0                   |
| stats_g/mean       | 0.10164529          |
| stats_g/std        | 1.0133612           |
| stats_o/mean       | -0.0016683415       |
| stats_o/std        | 1.1944373           |
| test/episode       | 20.0                |
| test/mean_Q        | -3.4185405          |
| test/reward        | -261.3749051321096  |
| test/steps         | 1000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 30.0                |
| train/reward       | -255.21911822400267 |
| train/steps        | 1500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_0.pkl ...
--------------------------------------------
| epoch              | 1                   |
| stats_g/mean       | 0.073345006         |
| stats_g/std        | 0.97628665          |
| stats_o/mean       | 0.02037855          |
| stats_o/std        | 1.144532            |
| test/episode       | 40.0                |
| test/mean_Q        | -4.2150693          |
| test/reward        | -208.09732404617824 |
| test/steps         | 2000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 60.0                |
| train/reward       | -197.31590755851585 |
| train/steps        | 3000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 2                   |
| stats_g/mean       | 0.04562831          |
| stats_g/std        | 0.97499645          |
| stats_o/mean       | 0.0005404614        |
| stats_o/std        | 1.1101177           |
| test/episode       | 60.0                |
| test/mean_Q        | -4.7507906          |
| test/reward        | -198.1926498681293  |
| test/steps         | 3000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 90.0                |
| train/reward       | -241.28583526881485 |
| train/steps        | 4500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 3                   |
| stats_g/mean       | 0.035398327         |
| stats_g/std        | 0.94613194          |
| stats_o/mean       | 9.3108974e-05       |
| stats_o/std        | 1.0811745           |
| test/episode       | 80.0                |
| test/mean_Q        | -5.3199434          |
| test/reward        | -207.07723784958532 |
| test/steps         | 4000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 120.0               |
| train/reward       | -215.17910321719478 |
| train/steps        | 6000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 4                   |
| stats_g/mean       | 0.03606794          |
| stats_g/std        | 0.92043734          |
| stats_o/mean       | -0.005112215        |
| stats_o/std        | 1.051465            |
| test/episode       | 100.0               |
| test/mean_Q        | -5.754739           |
| test/reward        | -98.69139867818237  |
| test/steps         | 5000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 150.0               |
| train/reward       | -194.17839289282986 |
| train/steps        | 7500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 5                   |
| stats_g/mean       | 0.016941145         |
| stats_g/std        | 0.9086168           |
| stats_o/mean       | -0.0059098713       |
| stats_o/std        | 1.0257759           |
| test/episode       | 120.0               |
| test/mean_Q        | -5.2575192          |
| test/reward        | -149.70194587386374 |
| test/steps         | 6000.0              |
| test/success_rate  | 0.025               |
| train/episode      | 180.0               |
| train/reward       | -181.99234777639344 |
| train/steps        | 9000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.025. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_5.pkl ...
--------------------------------------------
| epoch              | 6                   |
| stats_g/mean       | 0.008355822         |
| stats_g/std        | 0.9028036           |
| stats_o/mean       | -0.014346851        |
| stats_o/std        | 0.9995128           |
| test/episode       | 140.0               |
| test/mean_Q        | -5.6535916          |
| test/reward        | -125.05699186519637 |
| test/steps         | 7000.0              |
| test/success_rate  | 0.05                |
| train/episode      | 210.0               |
| train/reward       | -133.1487585629523  |
| train/steps        | 10500.0             |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.05. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 7                   |
| stats_g/mean       | 0.0033988205        |
| stats_g/std        | 0.8995127           |
| stats_o/mean       | -0.02661128         |
| stats_o/std        | 0.9809622           |
| test/episode       | 160.0               |
| test/mean_Q        | -5.5696707          |
| test/reward        | -79.0987685191153   |
| test/steps         | 8000.0              |
| test/success_rate  | 0.125               |
| train/episode      | 240.0               |
| train/reward       | -187.35963645640686 |
| train/steps        | 12000.0             |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.125. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 8                   |
| stats_g/mean       | -0.0038791979       |
| stats_g/std        | 0.89501286          |
| stats_o/mean       | -0.02267534         |
| stats_o/std        | 0.96087             |
| test/episode       | 180.0               |
| test/mean_Q        | -5.0429835          |
| test/reward        | -85.32964144632236  |
| test/steps         | 9000.0              |
| test/success_rate  | 0.175               |
| train/episode      | 270.0               |
| train/reward       | -105.31436370190973 |
| train/steps        | 13500.0             |
| train/success_rate | 0.03333333333333333 |
--------------------------------------------
New best success rate: 0.175. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 9                   |
| stats_g/mean       | -0.0015164323       |
| stats_g/std        | 0.89114225          |
| stats_o/mean       | -0.020558435        |
| stats_o/std        | 0.9454006           |
| test/episode       | 200.0               |
| test/mean_Q        | -5.025555           |
| test/reward        | -69.30582342903571  |
| test/steps         | 10000.0             |
| test/success_rate  | 0.325               |
| train/episode      | 300.0               |
| train/reward       | -113.28023367079723 |
| train/steps        | 15000.0             |
| train/success_rate | 0.06666666666666667 |
--------------------------------------------
New best success rate: 0.325. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 10                  |
| stats_g/mean       | 0.0028228979        |
| stats_g/std        | 0.8904266           |
| stats_o/mean       | -0.014601466        |
| stats_o/std        | 0.93262494          |
| test/episode       | 220.0               |
| test/mean_Q        | -5.8051653          |
| test/reward        | -64.8065681048815   |
| test/steps         | 11000.0             |
| test/success_rate  | 0.6                 |
| train/episode      | 330.0               |
| train/reward       | -116.50016889136546 |
| train/steps        | 16500.0             |
| train/success_rate | 0.13333333333333333 |
--------------------------------------------
New best success rate: 0.6. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_10.pkl ...
--------------------------------------------
| epoch              | 11                  |
| stats_g/mean       | -0.0030722301       |
| stats_g/std        | 0.89436936          |
| stats_o/mean       | -0.01402393         |
| stats_o/std        | 0.92394996          |
| test/episode       | 240.0               |
| test/mean_Q        | -5.6997714          |
| test/reward        | -99.38523377983816  |
| test/steps         | 12000.0             |
| test/success_rate  | 0.6                 |
| train/episode      | 360.0               |
| train/reward       | -110.46866517596204 |
| train/steps        | 18000.0             |
| train/success_rate | 0.18333333333333335 |
--------------------------------------------
New best success rate: 0.6. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
-------------------------------------------
| epoch              | 12                 |
| stats_g/mean       | -0.0022001495      |
| stats_g/std        | 0.89301264         |
| stats_o/mean       | -0.015527244       |
| stats_o/std        | 0.91453445         |
| test/episode       | 260.0              |
| test/mean_Q        | -5.8552246         |
| test/reward        | -93.15910998640418 |
| test/steps         | 13000.0            |
| test/success_rate  | 0.775              |
| train/episode      | 390.0              |
| train/reward       | -66.68296100128646 |
| train/steps        | 19500.0            |
| train/success_rate | 0.3                |
-------------------------------------------
New best success rate: 0.775. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
-------------------------------------------
| epoch              | 13                 |
| stats_g/mean       | -0.012236275       |
| stats_g/std        | 0.892219           |
| stats_o/mean       | -0.016733263       |
| stats_o/std        | 0.9048339          |
| test/episode       | 280.0              |
| test/mean_Q        | -5.953139          |
| test/reward        | -71.487790070714   |
| test/steps         | 14000.0            |
| test/success_rate  | 0.825              |
| train/episode      | 420.0              |
| train/reward       | -75.46695221467827 |
| train/steps        | 21000.0            |
| train/success_rate | 0.15               |
-------------------------------------------
New best success rate: 0.825. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 14                  |
| stats_g/mean       | -0.008311975        |
| stats_g/std        | 0.89311266          |
| stats_o/mean       | -0.013778553        |
| stats_o/std        | 0.89775527          |
| test/episode       | 300.0               |
| test/mean_Q        | -4.925806           |
| test/reward        | -24.491852602720382 |
| test/steps         | 15000.0             |
| test/success_rate  | 0.775               |
| train/episode      | 450.0               |
| train/reward       | -95.25695030699453  |
| train/steps        | 22500.0             |
| train/success_rate | 0.18333333333333335 |
--------------------------------------------
--------------------------------------------
| epoch              | 15                  |
| stats_g/mean       | -0.004148391        |
| stats_g/std        | 0.89535594          |
| stats_o/mean       | -0.01405            |
| stats_o/std        | 0.8911437           |
| test/episode       | 320.0               |
| test/mean_Q        | -5.5417957          |
| test/reward        | -49.41398059613378  |
| test/steps         | 16000.0             |
| test/success_rate  | 0.7                 |
| train/episode      | 480.0               |
| train/reward       | -93.67557491944115  |
| train/steps        | 24000.0             |
| train/success_rate | 0.21666666666666667 |
--------------------------------------------
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-0/policy_15.pkl ...
--------------------------------------------
| epoch              | 16                  |
| stats_g/mean       | 0.0021829447        |
| stats_g/std        | 0.8956293           |
| stats_o/mean       | -0.013251152        |
| stats_o/std        | 0.8851468           |
| test/episode       | 340.0               |
| test/mean_Q        | -6.8581944          |
| test/reward        | -64.83044816908954  |
| test/steps         | 17000.0             |
| test/success_rate  | 0.3                 |
| train/episode      | 510.0               |
| train/reward       | -103.21714314953533 |
| train/steps        | 25500.0             |
| train/success_rate | 0.13333333333333333 |
--------------------------------------------
--------------------------------------------
| epoch              | 17                  |
| stats_g/mean       | 0.0035179085        |
| stats_g/std        | 0.89766705          |
| stats_o/mean       | -0.011505061        |
| stats_o/std        | 0.88077295          |
| test/episode       | 360.0               |
| test/mean_Q        | -5.9866295          |
| test/reward        | -66.61238332088828  |
| test/steps         | 18000.0             |
| test/success_rate  | 0.07500000000000001 |
| train/episode      | 540.0               |
| train/reward       | -108.30521075057425 |
| train/steps        | 27000.0             |
| train/success_rate | 0.1                 |
--------------------------------------------
-------------------------------------------
| epoch              | 18                 |
| stats_g/mean       | 0.00078007224      |
| stats_g/std        | 0.89798975         |
| stats_o/mean       | -0.012112427       |
| stats_o/std        | 0.87632656         |
| test/episode       | 380.0              |
| test/mean_Q        | -7.000331          |
| test/reward        | -94.52439661844497 |
| test/steps         | 19000.0            |
| test/success_rate  | 0.375              |
| train/episode      | 570.0              |
| train/reward       | -97.01390351441893 |
| train/steps        | 28500.0            |
| train/success_rate | 0.2                |
-------------------------------------------
---------------------------------------------
| epoch              | 19                   |
| stats_g/mean       | 0.0014546437         |
| stats_g/std        | 0.89961374           |
| stats_o/mean       | -0.011209855         |
| stats_o/std        | 0.8751761            |
| test/episode       | 400.0                |
| test/mean_Q        | -5.8760204           |
| test/reward        | -67.45854796320097   |
| test/steps         | 20000.0              |
| test/success_rate  | 0.6499999999999999   |
| train/episode      | 600.0                |
| train/reward       | -115.21970421616675  |
| train/steps        | 30000.0              |
| train/success_rate | 0.016666666666666666 |
---------------------------------------------
