Logging to /home/adarshsehgal/AACHER_logs/A1C3-0
T: 50
_Q_lr: 0.001
_action_l2: 1.0
_batch_size: 32
_buffer_size: 1000000
_clip_obs: 200.0
_hidden: 128
_layers: 2
_max_u: 1.7
_network_class: multi_actor_critic:MultiActorCritic
_norm_clip: 5
_norm_eps: 0.01
_number_actors_main: 1
_number_actors_target: 1
_number_critics_main: 3
_number_critics_target: 3
_pi_lr: 0.001
_polyak: 0.95
_relative_goals: False
_scope: ddpg
central_tendency: mean
ddpg_params: {'buffer_size': 1000000, 'hidden': 128, 'layers': 2, 'network_class': 'multi_actor_critic:MultiActorCritic', 'polyak': 0.95, 'batch_size': 32, 'Q_lr': 0.001, 'pi_lr': 0.001, 'norm_eps': 0.01, 'norm_clip': 5, 'max_u': 1.7, 'action_l2': 1.0, 'clip_obs': 200.0, 'scope': 'ddpg', 'relative_goals': False, 'number_actors_main': 1, 'number_critics_main': 3, 'number_actors_target': 1, 'number_critics_target': 3}
env_name: AuboReach-v5
gamma: 0.98
make_env: <function prepare_params.<locals>.make_env at 0x7fdbc2c266a8>
n_batches: 15
n_cycles: 15
n_test_rollouts: 10
noise_eps: 0.2
random_eps: 0.3
replay_k: 4
replay_strategy: future
rl_algo: ddpg_multi_actor_critic
rollout_batch_size: 2
test_with_polyak: False
Creating a DDPGMultiActorCritic agent with action space 4 x 1.7...
Training...
--------------------------------------------
| epoch              | 0                   |
| stats_g/mean       | -0.03527802         |
| stats_g/std        | 0.97959423          |
| stats_o/mean       | -0.027299307        |
| stats_o/std        | 1.0703876           |
| test/episode       | 20.0                |
| test/mean_Q        | -3.10094            |
| test/reward        | -146.01346346424884 |
| test/steps         | 1000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 30.0                |
| train/reward       | -209.3586807871787  |
| train/steps        | 1500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_0.pkl ...
--------------------------------------------
| epoch              | 1                   |
| stats_g/mean       | 0.009873189         |
| stats_g/std        | 0.93800515          |
| stats_o/mean       | -0.021402264        |
| stats_o/std        | 1.0933287           |
| test/episode       | 40.0                |
| test/mean_Q        | -4.0549583          |
| test/reward        | -190.52928335838084 |
| test/steps         | 2000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 60.0                |
| train/reward       | -233.07669638042074 |
| train/steps        | 3000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 2                   |
| stats_g/mean       | 0.0017317533        |
| stats_g/std        | 0.9142167           |
| stats_o/mean       | -0.01899938         |
| stats_o/std        | 1.0601637           |
| test/episode       | 60.0                |
| test/mean_Q        | -4.676919           |
| test/reward        | -160.4712009347558  |
| test/steps         | 3000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 90.0                |
| train/reward       | -132.02184123577516 |
| train/steps        | 4500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 3                   |
| stats_g/mean       | -0.010289342        |
| stats_g/std        | 0.8985837           |
| stats_o/mean       | -0.012108963        |
| stats_o/std        | 1.0422292           |
| test/episode       | 80.0                |
| test/mean_Q        | -4.9835143          |
| test/reward        | -99.74097976737362  |
| test/steps         | 4000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 120.0               |
| train/reward       | -153.44664321554194 |
| train/steps        | 6000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 4                   |
| stats_g/mean       | -0.007564322        |
| stats_g/std        | 0.8851372           |
| stats_o/mean       | -0.015228256        |
| stats_o/std        | 1.009985            |
| test/episode       | 100.0               |
| test/mean_Q        | -4.511669           |
| test/reward        | -99.56651640543531  |
| test/steps         | 5000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 150.0               |
| train/reward       | -109.99667516944999 |
| train/steps        | 7500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 5                   |
| stats_g/mean       | -0.003834472        |
| stats_g/std        | 0.8820517           |
| stats_o/mean       | -0.020604823        |
| stats_o/std        | 0.9882679           |
| test/episode       | 120.0               |
| test/mean_Q        | -5.140723           |
| test/reward        | -122.87144006947858 |
| test/steps         | 6000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 180.0               |
| train/reward       | -154.9059701353682  |
| train/steps        | 9000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_5.pkl ...
--------------------------------------------
| epoch              | 6                   |
| stats_g/mean       | 0.0018796166        |
| stats_g/std        | 0.8799045           |
| stats_o/mean       | -0.015805013        |
| stats_o/std        | 0.9661491           |
| test/episode       | 140.0               |
| test/mean_Q        | -5.0804734          |
| test/reward        | -93.77103278621084  |
| test/steps         | 7000.0              |
| test/success_rate  | 0.05                |
| train/episode      | 210.0               |
| train/reward       | -144.45422096978012 |
| train/steps        | 10500.0             |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.05. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
---------------------------------------------
| epoch              | 7                    |
| stats_g/mean       | -0.004314062         |
| stats_g/std        | 0.877705             |
| stats_o/mean       | -0.010302126         |
| stats_o/std        | 0.9488055            |
| test/episode       | 160.0                |
| test/mean_Q        | -4.553707            |
| test/reward        | -100.54740083920157  |
| test/steps         | 8000.0               |
| test/success_rate  | 0.15                 |
| train/episode      | 240.0                |
| train/reward       | -147.7524796042216   |
| train/steps        | 12000.0              |
| train/success_rate | 0.016666666666666666 |
---------------------------------------------
New best success rate: 0.15. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 8                   |
| stats_g/mean       | -0.0079579875       |
| stats_g/std        | 0.88394374          |
| stats_o/mean       | -0.010247372        |
| stats_o/std        | 0.93797415          |
| test/episode       | 180.0               |
| test/mean_Q        | -4.8752117          |
| test/reward        | -86.08439699574441  |
| test/steps         | 9000.0              |
| test/success_rate  | 0.2                 |
| train/episode      | 270.0               |
| train/reward       | -118.31197466507314 |
| train/steps        | 13500.0             |
| train/success_rate | 0.09999999999999999 |
--------------------------------------------
New best success rate: 0.2. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
-------------------------------------------
| epoch              | 9                  |
| stats_g/mean       | 0.0031274417       |
| stats_g/std        | 0.8864234          |
| stats_o/mean       | -0.012973333       |
| stats_o/std        | 0.92814016         |
| test/episode       | 200.0              |
| test/mean_Q        | -4.6617355         |
| test/reward        | -69.62179868604966 |
| test/steps         | 10000.0            |
| test/success_rate  | 0.8                |
| train/episode      | 300.0              |
| train/reward       | -149.654960023242  |
| train/steps        | 15000.0            |
| train/success_rate | 0.15               |
-------------------------------------------
New best success rate: 0.8. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 10                  |
| stats_g/mean       | 0.005642094         |
| stats_g/std        | 0.8812397           |
| stats_o/mean       | -0.011618009        |
| stats_o/std        | 0.91574967          |
| test/episode       | 220.0               |
| test/mean_Q        | -5.1955004          |
| test/reward        | -62.58723722207715  |
| test/steps         | 11000.0             |
| test/success_rate  | 0.725               |
| train/episode      | 330.0               |
| train/reward       | -111.82078133245442 |
| train/steps        | 16500.0             |
| train/success_rate | 0.21666666666666667 |
--------------------------------------------
Saving periodic policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_10.pkl ...
--------------------------------------------
| epoch              | 11                  |
| stats_g/mean       | 0.0002823742        |
| stats_g/std        | 0.8831308           |
| stats_o/mean       | -0.0135390265       |
| stats_o/std        | 0.9069489           |
| test/episode       | 240.0               |
| test/mean_Q        | -5.356586           |
| test/reward        | -48.195379752448176 |
| test/steps         | 12000.0             |
| test/success_rate  | 0.825               |
| train/episode      | 360.0               |
| train/reward       | -148.79265596210422 |
| train/steps        | 18000.0             |
| train/success_rate | 0.2                 |
--------------------------------------------
New best success rate: 0.825. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 12                  |
| stats_g/mean       | -0.0015599262       |
| stats_g/std        | 0.8821981           |
| stats_o/mean       | -0.012038077        |
| stats_o/std        | 0.89743793          |
| test/episode       | 260.0               |
| test/mean_Q        | -5.3425856          |
| test/reward        | -125.5532901701588  |
| test/steps         | 13000.0             |
| test/success_rate  | 1.0                 |
| train/episode      | 390.0               |
| train/reward       | -93.17389707624585  |
| train/steps        | 19500.0             |
| train/success_rate | 0.43333333333333335 |
--------------------------------------------
New best success rate: 1.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
--------------------------------------------
| epoch              | 13                  |
| stats_g/mean       | 0.0019007819        |
| stats_g/std        | 0.882068            |
| stats_o/mean       | -0.013473407        |
| stats_o/std        | 0.8914786           |
| test/episode       | 280.0               |
| test/mean_Q        | -4.6708574          |
| test/reward        | -76.84152179431592  |
| test/steps         | 14000.0             |
| test/success_rate  | 0.975               |
| train/episode      | 420.0               |
| train/reward       | -179.18408818693086 |
| train/steps        | 21000.0             |
| train/success_rate | 0.23333333333333334 |
--------------------------------------------
-------------------------------------------
| epoch              | 14                 |
| stats_g/mean       | 0.0054360153       |
| stats_g/std        | 0.88384676         |
| stats_o/mean       | -0.013283458       |
| stats_o/std        | 0.88613033         |
| test/episode       | 300.0              |
| test/mean_Q        | -5.2250276         |
| test/reward        | -43.35677506884633 |
| test/steps         | 15000.0            |
| test/success_rate  | 1.0                |
| train/episode      | 450.0              |
| train/reward       | -69.61938117700106 |
| train/steps        | 22500.0            |
| train/success_rate | 0.2833333333333333 |
-------------------------------------------
New best success rate: 1.0. Saving policy to /home/adarshsehgal/AACHER_logs/A1C3-0/policy_best.pkl ...
