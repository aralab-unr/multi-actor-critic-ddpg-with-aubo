Logging to /home/adarshsehgal/AACHER_logs/DRL-1
T: 50
_Q_lr: 0.001
_action_l2: 1.0
_batch_size: 32
_buffer_size: 1000000
_clip_obs: 200.0
_hidden: 128
_layers: 2
_max_u: 1.7
_network_class: actor_critic:ActorCritic
_norm_clip: 5
_norm_eps: 0.01
_number_actors_main: 1
_number_actors_target: 1
_number_critics_main: 3
_number_critics_target: 3
_pi_lr: 0.001
_polyak: 0.95
_relative_goals: False
_scope: ddpg
central_tendency: mean
ddpg_params: {'buffer_size': 1000000, 'hidden': 128, 'layers': 2, 'network_class': 'actor_critic:ActorCritic', 'polyak': 0.95, 'batch_size': 32, 'Q_lr': 0.001, 'pi_lr': 0.001, 'norm_eps': 0.01, 'norm_clip': 5, 'max_u': 1.7, 'action_l2': 1.0, 'clip_obs': 200.0, 'scope': 'ddpg', 'relative_goals': False, 'number_actors_main': 1, 'number_critics_main': 3, 'number_actors_target': 1, 'number_critics_target': 3}
env_name: AuboReach-v5
gamma: 0.98
make_env: <function prepare_params.<locals>.make_env at 0x7f58fccd9268>
n_batches: 15
n_cycles: 15
n_test_rollouts: 10
noise_eps: 0.2
random_eps: 0.3
replay_k: 4
replay_strategy: future
rl_algo: ddpg
rollout_batch_size: 2
test_with_polyak: False
Creating a DDPG agent with action space 4 x 1.7...
Training...
--------------------------------------------
| epoch              | 0                   |
| stats_g/mean       | 0.097874865         |
| stats_g/std        | 1.0605052           |
| stats_o/mean       | 0.09485912          |
| stats_o/std        | 1.2632568           |
| test/episode       | 20.0                |
| test/mean_Q        | -4.0839853          |
| test/reward        | -302.39945967380993 |
| test/steps         | 1000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 30.0                |
| train/reward       | -247.14600630950545 |
| train/steps        | 1500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_0.pkl ...
--------------------------------------------
| epoch              | 1                   |
| stats_g/mean       | 0.055159986         |
| stats_g/std        | 0.99602455          |
| stats_o/mean       | 0.026463114         |
| stats_o/std        | 1.1983863           |
| test/episode       | 40.0                |
| test/mean_Q        | -4.3316374          |
| test/reward        | -217.69267733919656 |
| test/steps         | 2000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 60.0                |
| train/reward       | -192.1963650702748  |
| train/steps        | 3000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 2                   |
| stats_g/mean       | 0.05246842          |
| stats_g/std        | 0.96859336          |
| stats_o/mean       | 0.04693856          |
| stats_o/std        | 1.1418536           |
| test/episode       | 60.0                |
| test/mean_Q        | -5.125804           |
| test/reward        | -212.97828991157655 |
| test/steps         | 3000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 90.0                |
| train/reward       | -185.3979644262734  |
| train/steps        | 4500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 3                   |
| stats_g/mean       | 0.028225746         |
| stats_g/std        | 0.9474665           |
| stats_o/mean       | 0.012632508         |
| stats_o/std        | 1.1050963           |
| test/episode       | 80.0                |
| test/mean_Q        | -5.415452           |
| test/reward        | -176.72493498774017 |
| test/steps         | 4000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 120.0               |
| train/reward       | -182.92480421108894 |
| train/steps        | 6000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 4                   |
| stats_g/mean       | 0.0028848606        |
| stats_g/std        | 0.92751837          |
| stats_o/mean       | 0.0094305575        |
| stats_o/std        | 1.065321            |
| test/episode       | 100.0               |
| test/mean_Q        | -5.382883           |
| test/reward        | -129.0312415460628  |
| test/steps         | 5000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 150.0               |
| train/reward       | -141.18103967461894 |
| train/steps        | 7500.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 5                   |
| stats_g/mean       | 0.009520687         |
| stats_g/std        | 0.92394555          |
| stats_o/mean       | 0.0052352003        |
| stats_o/std        | 1.0383235           |
| test/episode       | 120.0               |
| test/mean_Q        | -5.849913           |
| test/reward        | -112.42844632799059 |
| test/steps         | 6000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 180.0               |
| train/reward       | -188.62710254744115 |
| train/steps        | 9000.0              |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_5.pkl ...
--------------------------------------------
| epoch              | 6                   |
| stats_g/mean       | 0.006413806         |
| stats_g/std        | 0.91750324          |
| stats_o/mean       | 0.0019236244        |
| stats_o/std        | 1.0166075           |
| test/episode       | 140.0               |
| test/mean_Q        | -6.024837           |
| test/reward        | -126.18728422201895 |
| test/steps         | 7000.0              |
| test/success_rate  | 0.0                 |
| train/episode      | 210.0               |
| train/reward       | -102.93020494577435 |
| train/steps        | 10500.0             |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.0. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 7                   |
| stats_g/mean       | 0.006994134         |
| stats_g/std        | 0.9145669           |
| stats_o/mean       | 0.0020792875        |
| stats_o/std        | 0.9947332           |
| test/episode       | 160.0               |
| test/mean_Q        | -4.808413           |
| test/reward        | -94.44770036488615  |
| test/steps         | 8000.0              |
| test/success_rate  | 0.025               |
| train/episode      | 240.0               |
| train/reward       | -152.44611477785025 |
| train/steps        | 12000.0             |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.025. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 8                   |
| stats_g/mean       | 0.016362727         |
| stats_g/std        | 0.91322184          |
| stats_o/mean       | 0.0016564922        |
| stats_o/std        | 0.97670436          |
| test/episode       | 180.0               |
| test/mean_Q        | -4.930929           |
| test/reward        | -79.96582449445219  |
| test/steps         | 9000.0              |
| test/success_rate  | 0.2                 |
| train/episode      | 270.0               |
| train/reward       | -110.58929754903357 |
| train/steps        | 13500.0             |
| train/success_rate | 0.0                 |
--------------------------------------------
New best success rate: 0.2. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 9                   |
| stats_g/mean       | 0.010985699         |
| stats_g/std        | 0.9088905           |
| stats_o/mean       | -0.0025038295       |
| stats_o/std        | 0.96060467          |
| test/episode       | 200.0               |
| test/mean_Q        | -6.0017357          |
| test/reward        | -69.41097327939518  |
| test/steps         | 10000.0             |
| test/success_rate  | 0.125               |
| train/episode      | 300.0               |
| train/reward       | -100.00062317336827 |
| train/steps        | 15000.0             |
| train/success_rate | 0.06666666666666667 |
--------------------------------------------
--------------------------------------------
| epoch              | 10                  |
| stats_g/mean       | 0.015726134         |
| stats_g/std        | 0.90792346          |
| stats_o/mean       | -0.0010695984       |
| stats_o/std        | 0.94929004          |
| test/episode       | 220.0               |
| test/mean_Q        | -5.069175           |
| test/reward        | -86.48823178085294  |
| test/steps         | 11000.0             |
| test/success_rate  | 0.7250000000000001  |
| train/episode      | 330.0               |
| train/reward       | -151.93419978955484 |
| train/steps        | 16500.0             |
| train/success_rate | 0.08333333333333334 |
--------------------------------------------
New best success rate: 0.7250000000000001. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_10.pkl ...
--------------------------------------------
| epoch              | 11                  |
| stats_g/mean       | 0.021657513         |
| stats_g/std        | 0.9033863           |
| stats_o/mean       | -0.005098458        |
| stats_o/std        | 0.9390365           |
| test/episode       | 240.0               |
| test/mean_Q        | -5.0178175          |
| test/reward        | -74.51810192731602  |
| test/steps         | 12000.0             |
| test/success_rate  | 0.6                 |
| train/episode      | 360.0               |
| train/reward       | -100.68387443068099 |
| train/steps        | 18000.0             |
| train/success_rate | 0.1                 |
--------------------------------------------
--------------------------------------------
| epoch              | 12                  |
| stats_g/mean       | 0.026014484         |
| stats_g/std        | 0.902647            |
| stats_o/mean       | -0.0022998648       |
| stats_o/std        | 0.9285239           |
| test/episode       | 260.0               |
| test/mean_Q        | -5.7133694          |
| test/reward        | -75.92952296197411  |
| test/steps         | 13000.0             |
| test/success_rate  | 0.6499999999999999  |
| train/episode      | 390.0               |
| train/reward       | -123.07574353214333 |
| train/steps        | 19500.0             |
| train/success_rate | 0.26666666666666666 |
--------------------------------------------
--------------------------------------------
| epoch              | 13                  |
| stats_g/mean       | 0.022196908         |
| stats_g/std        | 0.9057903           |
| stats_o/mean       | 0.0014095185        |
| stats_o/std        | 0.92158246          |
| test/episode       | 280.0               |
| test/mean_Q        | -6.0496817          |
| test/reward        | -62.74845100260671  |
| test/steps         | 14000.0             |
| test/success_rate  | 0.575               |
| train/episode      | 420.0               |
| train/reward       | -152.77134731085795 |
| train/steps        | 21000.0             |
| train/success_rate | 0.33333333333333337 |
--------------------------------------------
--------------------------------------------
| epoch              | 14                  |
| stats_g/mean       | 0.01584895          |
| stats_g/std        | 0.9065571           |
| stats_o/mean       | 0.0026041577        |
| stats_o/std        | 0.9125446           |
| test/episode       | 300.0               |
| test/mean_Q        | -6.286577           |
| test/reward        | -62.397726045835924 |
| test/steps         | 15000.0             |
| test/success_rate  | 0.4                 |
| train/episode      | 450.0               |
| train/reward       | -91.2523838080944   |
| train/steps        | 22500.0             |
| train/success_rate | 0.2                 |
--------------------------------------------
--------------------------------------------
| epoch              | 15                  |
| stats_g/mean       | 0.0151962945        |
| stats_g/std        | 0.9035756           |
| stats_o/mean       | -1.576636e-05       |
| stats_o/std        | 0.9044874           |
| test/episode       | 320.0               |
| test/mean_Q        | -6.590782           |
| test/reward        | -90.51182206025538  |
| test/steps         | 16000.0             |
| test/success_rate  | 0.375               |
| train/episode      | 480.0               |
| train/reward       | -96.48367792986934  |
| train/steps        | 24000.0             |
| train/success_rate | 0.16666666666666669 |
--------------------------------------------
Saving periodic policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_15.pkl ...
--------------------------------------------
| epoch              | 16                  |
| stats_g/mean       | 0.017085016         |
| stats_g/std        | 0.9034818           |
| stats_o/mean       | 0.0015047197        |
| stats_o/std        | 0.8983846           |
| test/episode       | 340.0               |
| test/mean_Q        | -7.4007854          |
| test/reward        | -104.34759112306654 |
| test/steps         | 17000.0             |
| test/success_rate  | 0.7                 |
| train/episode      | 510.0               |
| train/reward       | -110.86528633782004 |
| train/steps        | 25500.0             |
| train/success_rate | 0.18333333333333335 |
--------------------------------------------
-------------------------------------------
| epoch              | 17                 |
| stats_g/mean       | 0.016573185        |
| stats_g/std        | 0.903651           |
| stats_o/mean       | 0.0010184702       |
| stats_o/std        | 0.89369327         |
| test/episode       | 360.0              |
| test/mean_Q        | -5.7729073         |
| test/reward        | -81.8186229858257  |
| test/steps         | 18000.0            |
| test/success_rate  | 0.7250000000000001 |
| train/episode      | 540.0              |
| train/reward       | -84.05213447434951 |
| train/steps        | 27000.0            |
| train/success_rate | 0.15               |
-------------------------------------------
New best success rate: 0.7250000000000001. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 18                  |
| stats_g/mean       | 0.016029006         |
| stats_g/std        | 0.9013325           |
| stats_o/mean       | -0.002082548        |
| stats_o/std        | 0.8879128           |
| test/episode       | 380.0               |
| test/mean_Q        | -6.047329           |
| test/reward        | -81.41638694523013  |
| test/steps         | 19000.0             |
| test/success_rate  | 0.775               |
| train/episode      | 570.0               |
| train/reward       | -140.91926976786078 |
| train/steps        | 28500.0             |
| train/success_rate | 0.15                |
--------------------------------------------
New best success rate: 0.775. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
--------------------------------------------
| epoch              | 19                  |
| stats_g/mean       | 0.016256642         |
| stats_g/std        | 0.90011495          |
| stats_o/mean       | -0.0013389983       |
| stats_o/std        | 0.88412654          |
| test/episode       | 400.0               |
| test/mean_Q        | -6.1156034          |
| test/reward        | -58.357935620706115 |
| test/steps         | 20000.0             |
| test/success_rate  | 0.8                 |
| train/episode      | 600.0               |
| train/reward       | -134.91676880306494 |
| train/steps        | 30000.0             |
| train/success_rate | 0.13333333333333333 |
--------------------------------------------
New best success rate: 0.8. Saving policy to /home/adarshsehgal/AACHER_logs/DRL-1/policy_best.pkl ...
